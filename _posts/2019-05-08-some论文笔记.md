---
layout:     post
title:      some论文笔记
subtitle:   recommender系统中的矩阵因式分解相关论文笔记
date:       2019-05-08
author:     wenmeiyu
header-img: img/post-bg-ios9-web.jpg
catalog: true
tags:
    - paper
---
# 参考资料

>[书籍原文下载链接](https://pan.baidu.com/s/1cdl7OotAbS5QP3eDuhOPyQ) 提取码：`jdt7`
>[Matrix Factorization Techniques for Recommender Systems](https://www.computer.org/csdl/magazine/co/2009/08/mco2009080030/13rRUxBa5fj)
>[l-Injection: Toward Effective Collaborative Filtering Using Uninteresting Items](https://ieeexplore.ieee.org/abstract/document/7913668)
>[A non negative matrix factorization for collaborative filtering recommender systems based on a Bayesian probabilistic model](https://www.sciencedirect.com/science/article/pii/S0950705115005006)

---
### Chapter1. How to Learn Bioinformatics 怎么学习生物信息学

- 目前，在世界各地的实验室，机器正在测量地球上的生命的基因组数据。即使伴随着在基因组测序的成本快速下降和技术巨大进步，我们仅仅能看到包含每一个细胞，组织，生物体和生态系统的生物信息的一瞥。但是，我们正在采集的整体生物信息的一小部分相当于生物学家们需要去处理的海量数据。在人类历史的其他点上，我们理解生活复杂性的能力从未如此依赖于我们处理和分析数据的技能。
- 这本书是关于通过发展数据技能来学习生物信息学。在本章中，我们将看到什么是数据技能，以及为什么学习数据技能是学习生物信息学的最佳方法。我们还将看看稳健和可重复的研究需要什么。

#### 1.1 Why Bioinformatics? Biology’s Growing Data 为什么是生物信息学？生物学不断扩大的数据

- 生物信息学家致力于用专业技能和工具从大量数据中获得生物学上的理解。在生物学的早期，数据集较小且易于管理。大多数的生物学家在上完一节统计学课之后，使用个人电脑上的Excel软件就可以分析他们自己的数据。然而，这一切正在快速改变。大型测序数据集分布广泛，而且在未来只会变得更加普遍。分析这些数据需要不同的工具，新的技术，很多有大量内存的电脑，处理能力和磁盘空间。
- 在相对较短的时间内，测序成本大幅下降，使得研究人员能够利用测序数据帮助回答重要的生物学问题。早期测序是低通量（low-throughput）和昂贵的。全基因组测序（Whole genome sequencing）的成本很高(人类基因组的成本约为27亿美元)，只有通过大规模的合作才能实现。自从人类基因组释放以来，测序成本在2008年呈指数下跌，就像图1-1@[1-1](https://raw.githubusercontent.com/wenmeiyu/wenmeiyu.github.io/master/_posts/image/figure1-1.png) 随着下一代测序技术(next-generation sequencing)的引入，对一个兆位DNA进行测序的成本下降得更快。在这个关键时刻，一项只有大型合作测序工作(或财力雄厚的单个研究人员)才负担得起的技术，成为了所有生物学领域的研究人员都负担得起的技术。你读这本书很可能是为了学习使用测序数据，而这些数据在10年前太昂贵无法生成。
- 由于这些新技术，测序成本下降的结果是什么?你可能已经猜到了，有很多很多的数据。生物数据库在经历了指数级增长后，随着数据的增加而膨胀。以前协作者之间共享的小型数据库就足够了，现在世界各地的服务器上都有pb级的有用数据。有关生物学问题的关键见解不仅存储在硬盘上未经分析的实验数据中，还存储在数千英里之外的数据中心的磁盘上。
- 生物数据库的增长和测序成本的下降一样令人震惊。例如，考虑序列读存档(Sequence Read Archive)(以前称为短读存档[Short Read Archive](http://bit.ly/seq-read) )，它是来自测序实验的原始测序数据的存储库。自2010年以来，它经历了显著的增长，如图1-2所示@[1-2](https://raw.githubusercontent.com/wenmeiyu/wenmeiyu.github.io/master/_posts/image/figure1-2.png)

#### 1.2 Learning Data Skills to Learn Bioinformatics  学习数据技能，学习生物信息学

- 生物数据的性质变化如此之快，你应该如何学习生物信息学?有了所有这些还在不断地被创造出来的工具，生物学家怎么可能知道一个程序是否会对她的生物体数据(organism’s data)起适当的作用呢?
- 解决方法是像生物信息学家那样对待生物信息学:尝试一些东西，然后评估结果。在这种情况下，生物信息学就是拥有使用计算机对数据进行实验并理解结果的技能。实验部分简单;这对大多数科学家来说很自然。对大多数生物学家来说，限制因素是拥有在计算机上自由实验和处理大量数据的数据技能。这本书的目的是教你必要的生物信息学数据技能，使你可以在计算机上实验数据，就像在实验室里做实验一样容易。
- 不幸的是，许多生物学家常用的计算工具无法扩展到现代生物数据的大小和复杂性。复杂的数据格式、众多程序的接口以及评估软件和数据使得大型生物信息学数据集难以处理。学习核心的生物信息学数据技能将为您学习、应用和评估任何生物信息学程序或分析方法提供基础。10年后，生物信息学家们可能只会在今天使用一些生物信息学软件程序。但我们肯定会使用数据技能(Data Skills)和实验来评估未来的数据和方法。
- 因此什么是数据技术(Data Skills)？它们是一组计算技能，使您能够使用一组众所周知的工具，快速地临时处理查看复杂数据集的方法。一个很好的类比就是爵士音乐家所说的“排骨(chops)”。一个有天赋的爵士音乐家可以走进一家夜总会，听到正在演奏的一首熟悉的标准歌曲，识别和弦的变化，并开始在这些和弦上演奏音乐理念。同样，具有良好数据技能的生物信息学家可以接收一个巨大的测序数据集，并立即开始使用一组工具来查看数据所讲述的故事。


# paper1 matrix factorization

matrix          矩阵
factorization  因式分解
techniques
for
recommender
systems

Koren, Yehuda, Robert Bell, and Chris Volinsky. "Matrix factorization techniques for recommender systems." Computer 8 (2009): 30-37.

#### 1.Abstract/Background   摘要/背景

Netflix Prize  competition  Netflix大奖赛

#### 2.Recommender system strategies 推荐系统策略

broadly speaking 广泛地说

- two strategies
	- content filtering 内容过滤
		- the Music Genome Project
		- the neighborhood methods and latent factor models

profile 轮廓，外形，简况，特征
genre 类型，种类
and so forth 等等
content-based strategies require gathering external information that might not be available or easy to collect   产品（电影/音乐）和用户特征信息不易采集
Music Genome Project  音乐基因组计划
alternative 选择性的，交替的

#### 3.Matrix factorization methods  矩阵因式分解方法

#### 4.A basic matrix factorization model  基于矩阵因式分解的模型
singular value decomposition(SVD)  奇异值分解

#### 5.Learning algorithms

- Stochastic gradient descent  随机的  梯度  下降    随机梯度下降
- Alternating least squares   交替的  最少的 平方    交替最小二乘  

#### 6.Adding biases  增加 偏差

#### 7.Additional input sources  额外的 输入 源

#### 8.Temporal dynamics   动力学  时间动态

#### 9.Inputs with varying confidence levels  具有不同置信水平的输入

#### 10.Netflix prize competition    Netflix大奖赛

extent 程度，范围

[一个关于这篇论文的理解](https://blog.csdn.net/weixin_42081343/article/details/80368298)

SVD(Singular Value Decomposition) 奇异值分解：

[一个用于降维的奇异值分解](https://www.cnblogs.com/pinard/p/6251584.html)
	- 相当于分解成为三个维数更小的矩阵
[一个SVD在推荐系统中的应用](https://www.cnblogs.com/lzllovesyl/p/5243370.html)
	- 优势在于：用户的评分数据是稀疏矩阵，可以用SVD将数据映射到低维空间，然后计算低维空间中的item之间的相似度，对用户未评分的item进行评分预测，最后将预测评分高的item推荐给用户。

## 论文翻译



 
---
# paper2 l-Injection

l-Injection  注射
toward  向
effecttive  有效的
collaborative  协同
filtering     过滤
using
uninteresting  无趣味的，乏味的
items

Collaborative Filtering  协同过滤

novel  稀奇的
framework  框架
sparsity 稀疏
unrated  未分级的

All **datasets** and codes that we used are available at:[https://goo.gl/KUrmip](https://goo.gl/KUrmip)
已下载哈哈哈哈哈

the Watcha dataset is privately  私下的
released from a Korean movie recommendation company
[http://watcha.net](http://watcha.net)

CCF-推荐的会议和期刊：[https://www.ccf.org.cn/xspj/gyml/](https://www.ccf.org.cn/xspj/gyml/)


#### 1.Introduction   介绍
preferences 偏好

#### 2.Preliminaries  预赛

#### 3.Proposed Approach  被提及的方法  提出 方法
- 3.1 Inferring Pre-Use Preferences  推理  使用前 偏爱，优先权
- 3.2 Identifying Uninteresting Items  识别  无趣的 目标
- 3.3 l-Injection  注射
- 3.4 Why Does the l-Injected Matrix Help?

#### 4.Experiments 实验

- 4.1 Experimental Setup   实验步骤

- 4.2 Inference of Pre-Use Preferences    推理  使用前 偏爱，优先权

- 4.3 User Satisfaction for Uninteresting Items  用户的 满意 无趣的 目标

- 4.4 Effect of l-Injection  影响

- 4.5 Accuracy of Modified CF Algorithms  精确度  改进的

- 4.6 Running Time of Modified CF Algorithms 改进的

- 4.7 Summary of Experimental Results   摘要  总结

#### 5.Related Work  相关工作

#### 6.Conclusions   总结

---
# review paper
杨博, 赵鹏飞. 推荐算法综述[J]. 山西大学学报(自然科学版), 2011, 34(3):337-350.
2 　问题及分析
2 .1 　稀疏性问题
实际应用中数据的稀疏性
2 .2 　可扩展性问题
算法复杂度
2 .3 　特征提取问题
基于内容推荐的多样性
2 .4 　其他问题
例如托攻击问题[ 63] 、隐私问题[ 64]

---
# paper3 non negative matrix factorization 

A non negative matrix factorization 非负矩阵因式分解
for collaborative filtering 
recommender systems 
based on a Bayesian probabilistic model

Knowledge-BasedSystems   ccf-c

#### abstract  
Our technique is based on factorizing  因式分解
the rating matrix 评分矩阵
into two non negative matrices 非负矩阵
whose components 成分
lie with in the range[0,1] with an understandable  
probabilistic  概率的
meaning.

#### 1.Introduction

Recommender systems 分为两大类:

- Based on contents.

- Based on collaborative filtering.
	- Based on Memory
	- Based on models

In our paper we will present an ovel technique for factoring the rating matrix, preserving the advantages of the classical factorization technique:

#### 4.Model

- 4.1 Over view of our technique

## 论文翻译

基于贝叶斯概率模型应用于协同过滤推荐系统的的非负矩阵因式分解

#### 摘要

在这篇文章中，我们提出了一个基于矩阵因式分解的推荐系统的预测用户尝试的新算法。我们的算法是基于分解评分矩阵为两个非负矩阵，矩阵的因素为一个可以理解的概率的意义以及范围在[0,1]区间。通过这个分解我们可以更加准确预测用户的评分，找出具有相似性的用户，同时调整和解释我们算法得出的推荐结果。

#### 1.引言

- 推荐系统是一类能够提供个性化推荐结果给用户的系统。推荐系统已经广泛用于不同的领域，例如音乐，电视剧，书籍，线上学习和电子商务。但是，大多数的论文研究主要关注电影的推荐。
- 推荐系统通常根据系统的输入分为两大类：
	- 基于内容。这一类推荐系统要求目标被一些特征和文字详细描述。因此，这些推荐系统需要用户告知他们不同类型的目标喜好的偏好。这个可以通过观察用户消费不同类型目标物品隐含地获取。
	- 基于协同过滤。这类推荐系统使用一个评分矩阵M对每一个用户提供关于他有多喜欢一些目标的信息。这类推荐系统
- 基于协同过滤的推荐系统可以根据推荐用户喜好所用的算法分为如下代表：
	- 基于记忆。
	- 基于模型。
- 在我们的论文中，我们提出一个分解评分矩阵的新方法，保持了经典的矩阵因式分解的优势。
	- 就像在经典的矩阵因式分解中，我们也考虑到了存在。。。
- 除了保持经典的矩阵因式分解的优势，我们的方法提供了额外的优势：
	- 在经典的矩阵因式分解算法中，矩阵因子可以是任意值，而我们的方法把它限制在[0,1]区间。
	- 区别于经典的矩阵因式分解。。。

#### 2.相关工作

#### 3.动机

#### 4.模型

- 本章我们将会提出本文的概率模型。4.1将会给出我们的方法的参数，输入和输出；4.2中我们提出关于用户评价目标的概率模型；4.3我们指出和我们模型相关的数学问题；4.4我们讨论分析算法的输出结果；4.5我们描述这个模型的学习算法；4.6我们最后指出方法的输出结果对模型参数的影响
- 4.1 我们的技术视图
	- 本章节我们提出算法的黑盒描述。这个算法对找到用户分享相同尝试的设置和预测一个用户喜欢一个目标的可能性很有用。
	- 输入
	- 参数 
---
# 其他资料及笔记

**协同过滤**：
- 协同过滤简单来说是利用某兴趣相投、拥有共同经验之群体的喜好来推荐用户感兴趣的信息，个人通过合作的机制给予信息相当程度的回应（如评分）并记录下来以达到过滤的目的进而帮助别人筛选信息，回应不一定局限于特别感兴趣的，特别不感兴趣信息的纪录也相当重要。
- 主要分为基于用户的协同过滤算法和基于物品的协同过滤算法。
	- 基于用户的协同过滤算法的关键是找到相同偏好的用户，找到了偏好最近的几个用户，他们偏好的物品便是要给你推荐的目标。
	- 基于物品的协同过滤算法的关键是计算其它物品和历史物品的相似度，相似度最近的几个物品便是要推荐的物品。
	- （换句话说，协同过滤算法的关键是解决**相似度问题**）。
	- 相似度计算主要有三个经典算法：余弦定理相似性度量、欧氏距离相似度度量和杰卡德相似性度量。
	- [一个协同过滤实现案例](https://blog.csdn.net/u012995888/article/details/79077681)

**矩阵因式分解**：
- 矩阵分解的思想很简单，对于用户-物品这个评分矩阵R，我们可以将其分解为用户-特性矩阵P，以及特性-物品矩阵Q。R=PQ。这样做的好处有两点： 
	- 1. 得到了用户的偏好，以及物品的特性 
	- 2. 降低了矩阵的维度。 

**疑问**：
- paper1 中的矩阵因式分解和SVD有什么区别？
	- 矩阵因式分解分为经典的矩阵因式分解和SVD等等
- 矩阵分解的方式有很多？包含paper3的非负矩阵因式分解，SVD奇异值分解等？
	- 是的

---
# 论文构想

5000 words TO 8000 words

- 加入评价文字的情感分析
- 爬取评分矩阵，获取情感分析矩阵，矩阵分解成向量，向量重新得到不再稀疏的评分结果，协同推荐相似度高用户和相似度高的目标
- 结果比对： 1. 相同数据集不同算法比较  2. 相同数据集不同算法比较，可比较多个算法











